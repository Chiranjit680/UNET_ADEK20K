{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c880005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHIRANJIT\\anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from UNet import Unet\n",
    "import utils\n",
    "import engine\n",
    "from learning_rate_range_test import LRTest\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43aaf3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 150, 388, 388])\n"
     ]
    }
   ],
   "source": [
    "model=Unet(channels=[3, 64, 128, 256, 512, 1024], no_classes=150)\n",
    "x   = torch.Tensor(np.random.rand(2, 3, 572, 572))\n",
    "y=model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3699418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir  = './ADE20K/images/training/'\n",
    "maskdir = './ADE20K/annotations/training/'\n",
    "val_datadir  = './ADE20K/images/validation/'\n",
    "val_maskdir = './ADE20K/annotations/validation/'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b66e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from scipy import ndimage\n",
    "\n",
    "class BaseDataSet(Dataset):\n",
    "    def __init__(self, root, split, mean, std, base_size=None, augment=True, val=False,\n",
    "                crop_size=321, scale=True, flip=True, rotate=False, blur=False, return_id=False):\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.augment = augment\n",
    "        self.crop_size = crop_size\n",
    "        if self.augment:\n",
    "            self.base_size = base_size\n",
    "            self.scale = scale\n",
    "            self.flip = flip\n",
    "            self.rotate = rotate\n",
    "            self.blur = blur\n",
    "        self.val = val\n",
    "        self.files = []\n",
    "        self._set_files()\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.normalize = transforms.Normalize(mean, std)\n",
    "        self.return_id = return_id\n",
    "\n",
    "        cv2.setNumThreads(0)\n",
    "\n",
    "    def _set_files(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _load_data(self, index):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _val_augmentation(self, image, label):\n",
    "        if self.crop_size:\n",
    "            h, w = label.shape\n",
    "            # Scale the smaller side to crop size\n",
    "            if h < w:\n",
    "                h, w = (self.crop_size, int(self.crop_size * w / h))\n",
    "            else:\n",
    "                h, w = (int(self.crop_size * h / w), self.crop_size)\n",
    "\n",
    "            image = cv2.resize(image, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "            label = Image.fromarray(label).resize((w, h), resample=Image.NEAREST)\n",
    "            label = np.asarray(label, dtype=np.int32)\n",
    "\n",
    "            # Center Crop\n",
    "            h, w = label.shape\n",
    "            start_h = (h - self.crop_size )// 2\n",
    "            start_w = (w - self.crop_size )// 2\n",
    "            end_h = start_h + self.crop_size\n",
    "            end_w = start_w + self.crop_size\n",
    "            image = image[start_h:end_h, start_w:end_w]\n",
    "            label = label[start_h:end_h, start_w:end_w]\n",
    "        return image, label\n",
    "\n",
    "    def _augmentation(self, image, label):\n",
    "        h, w, _ = image.shape\n",
    "        # Scaling, we set the bigger to base size, and the smaller \n",
    "        # one is rescaled to maintain the same ratio, if we don't have any obj in the image, re-do the processing\n",
    "        if self.base_size:\n",
    "            if self.scale:\n",
    "                longside = random.randint(int(self.base_size*0.5), int(self.base_size*2.0))\n",
    "            else:\n",
    "                longside = self.base_size\n",
    "            h, w = (longside, int(1.0 * longside * w / h + 0.5)) if h > w else (int(1.0 * longside * h / w + 0.5), longside)\n",
    "            image = cv2.resize(image, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "            label = cv2.resize(label, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "        h, w, _ = image.shape\n",
    "        # Rotate the image with an angle between -10 and 10\n",
    "        if self.rotate:\n",
    "            angle = random.randint(-10, 10)\n",
    "            center = (w / 2, h / 2)\n",
    "            rot_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            image = cv2.warpAffine(image, rot_matrix, (w, h), flags=cv2.INTER_LINEAR)#, borderMode=cv2.BORDER_REFLECT)\n",
    "            label = cv2.warpAffine(label, rot_matrix, (w, h), flags=cv2.INTER_NEAREST)#,  borderMode=cv2.BORDER_REFLECT)\n",
    "\n",
    "        # Padding to return the correct crop size\n",
    "        if self.crop_size:\n",
    "            pad_h = max(self.crop_size - h, 0)\n",
    "            pad_w = max(self.crop_size - w, 0)\n",
    "            pad_kwargs = {\n",
    "                \"top\": 0,\n",
    "                \"bottom\": pad_h,\n",
    "                \"left\": 0,\n",
    "                \"right\": pad_w,\n",
    "                \"borderType\": cv2.BORDER_CONSTANT,}\n",
    "            if pad_h > 0 or pad_w > 0:\n",
    "                image = cv2.copyMakeBorder(image, value=0, **pad_kwargs)\n",
    "                label = cv2.copyMakeBorder(label, value=0, **pad_kwargs)\n",
    "            \n",
    "            # Cropping \n",
    "            h, w, _ = image.shape\n",
    "            start_h = random.randint(0, h - self.crop_size)\n",
    "            start_w = random.randint(0, w - self.crop_size)\n",
    "            end_h = start_h + self.crop_size\n",
    "            end_w = start_w + self.crop_size\n",
    "            image = image[start_h:end_h, start_w:end_w]\n",
    "            label = label[start_h:end_h, start_w:end_w]\n",
    "\n",
    "        # Random H flip\n",
    "        if self.flip:\n",
    "            if random.random() > 0.5:\n",
    "                image = np.fliplr(image).copy()\n",
    "                label = np.fliplr(label).copy()\n",
    "\n",
    "        # Gaussian Blud (sigma between 0 and 1.5)\n",
    "        if self.blur:\n",
    "            sigma = random.random()\n",
    "            ksize = int(3.3 * sigma)\n",
    "            ksize = ksize + 1 if ksize % 2 == 0 else ksize\n",
    "            image = cv2.GaussianBlur(image, (ksize, ksize), sigmaX=sigma, sigmaY=sigma, borderType=cv2.BORDER_REFLECT_101)\n",
    "        return image, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label, image_id = self._load_data(index)\n",
    "        if self.val:\n",
    "            image, label = self._val_augmentation(image, label)\n",
    "        elif self.augment:\n",
    "            image, label = self._augmentation(image, label)\n",
    "\n",
    "        label = torch.from_numpy(np.array(label, dtype=np.int32)).long()\n",
    "        image = Image.fromarray(np.uint8(image))\n",
    "        if self.return_id:\n",
    "            return  self.normalize(self.to_tensor(image)), label, image_id\n",
    "        return self.normalize(self.to_tensor(image)), label\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = \"Dataset: \" + self.__class__.__name__ + \"\\n\"\n",
    "        fmt_str += \"    # data: {}\\n\".format(self.__len__())\n",
    "        fmt_str += \"    Split: {}\\n\".format(self.split)\n",
    "        fmt_str += \"    Root: {}\".format(self.root)\n",
    "        return fmt_str\n",
    "\n",
    "class BaseDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, batch_size, shuffle, num_workers, val_split = 0.0):\n",
    "        self.shuffle = shuffle\n",
    "        self.dataset = dataset\n",
    "        self.nbr_examples = len(dataset)\n",
    "        if val_split: self.train_sampler, self.val_sampler = self._split_sampler(val_split)\n",
    "        else: self.train_sampler, self.val_sampler = None, None\n",
    "\n",
    "        self.init_kwargs = {\n",
    "            'dataset': self.dataset,\n",
    "            'batch_size': batch_size,\n",
    "            'shuffle': self.shuffle,\n",
    "            'num_workers': num_workers,\n",
    "            'pin_memory': True\n",
    "        }\n",
    "        super(BaseDataLoader, self).__init__(sampler=self.train_sampler, **self.init_kwargs)\n",
    "\n",
    "    def _split_sampler(self, split):\n",
    "        if split == 0.0:\n",
    "            return None, None\n",
    "        \n",
    "        self.shuffle = False\n",
    "\n",
    "        split_indx = int(self.nbr_examples * split)\n",
    "        np.random.seed(0)\n",
    "        \n",
    "        indxs = np.arange(self.nbr_examples)\n",
    "        np.random.shuffle(indxs)\n",
    "        train_indxs = indxs[split_indx:]\n",
    "        val_indxs = indxs[:split_indx]\n",
    "        self.nbr_examples = len(train_indxs)\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(train_indxs)\n",
    "        val_sampler = SubsetRandomSampler(val_indxs)\n",
    "        return train_sampler, val_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21d48020",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADE20K_palette = [0,0,0,120,120,120,180,120,120,6,230,230,80,50,50,4,200,\n",
    "                    3,120,120,80,140,140,140,204,5,255,230,230,230,4,250,7,224,\n",
    "                    5,255,235,255,7,150,5,61,120,120,70,8,255,51,255,6,82,143,\n",
    "                    255,140,204,255,4,255,51,7,204,70,3,0,102,200,61,230,250,255,\n",
    "                    6,51,11,102,255,255,7,71,255,9,224,9,7,230,220,220,220,255,9,\n",
    "                    92,112,9,255,8,255,214,7,255,224,255,184,6,10,255,71,255,41,\n",
    "                    10,7,255,255,224,255,8,102,8,255,255,61,6,255,194,7,255,122,8,\n",
    "                    0,255,20,255,8,41,255,5,153,6,51,255,235,12,255,160,150,20,0,\n",
    "                    163,255,140,140,140,250,10,15,20,255,0,31,255,0,255,31,0,255,224\n",
    "                    ,0,153,255,0,0,0,255,255,71,0,0,235,255,0,173,255,31,0,255,11,200,\n",
    "                    200,255,82,0,0,255,245,0,61,255,0,255,112,0,255,133,255,0,0,255,\n",
    "                    163,0,255,102,0,194,255,0,0,143,255,51,255,0,0,82,255,0,255,41,0,\n",
    "                    255,173,10,0,255,173,255,0,0,255,153,255,92,0,255,0,255,255,0,245,\n",
    "                    255,0,102,255,173,0,255,0,20,255,184,184,0,31,255,0,255,61,0,71,255,\n",
    "                    255,0,204,0,255,194,0,255,82,0,10,255,0,112,255,51,0,255,0,194,255,0,\n",
    "                    122,255,0,255,163,255,153,0,0,255,10,255,112,0,143,255,0,82,0,255,163,\n",
    "                    255,0,255,235,0,8,184,170,133,0,255,0,255,92,184,0,255,255,0,31,0,184,\n",
    "                    255,0,214,255,255,0,112,92,255,0,0,224,255,112,224,255,70,184,160,163,\n",
    "                    0,255,153,0,255,71,255,0,255,0,163,255,204,0,255,0,143,0,255,235,133,255,\n",
    "                    0,255,0,235,245,0,255,255,0,122,255,245,0,10,190,212,214,255,0,0,204,255,\n",
    "                    20,0,255,255,255,0,0,153,255,0,41,255,0,255,204,41,0,255,41,255,0,173,0,\n",
    "                    255,0,245,255,71,0,255,122,0,255,0,255,184,0,92,255,184,255,0,0,133,255,\n",
    "                    255,214,0,25,194,194,102,255,0,92,0,255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9ea7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what's in the base directory\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class ADE20KDataset(BaseDataSet):\n",
    "    \"\"\"\n",
    "    ADE20K dataset \n",
    "    http://groups.csail.mit.edu/vision/datasets/ADE20K/\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.num_classes = 150\n",
    "        self.palette = ADE20K_palette\n",
    "        super(ADE20KDataset, self).__init__(**kwargs)\n",
    "\n",
    "    def _set_files(self):\n",
    "        if self.split in  [\"training\", \"validation\"]:\n",
    "            self.image_dir = os.path.join(self.root, 'images', self.split)\n",
    "            self.label_dir = os.path.join(self.root, 'annotations', self.split)\n",
    "            self.files = [os.path.basename(path).split('.')[0] for path in glob(self.image_dir + '/*.jpg')]\n",
    "        else: raise ValueError(f\"Invalid split name {self.split}\")\n",
    "    \n",
    "    def _load_data(self, index):\n",
    "        image_id = self.files[index]\n",
    "        image_path = os.path.join(self.image_dir, image_id + '.jpg')\n",
    "        label_path = os.path.join(self.label_dir, image_id + '.png')\n",
    "        image = np.asarray(Image.open(image_path).convert('RGB'), dtype=np.float32)\n",
    "        label = np.asarray(Image.open(label_path), dtype=np.int32) - 1 # from -1 to 149\n",
    "        return image, label, image_id\n",
    "\n",
    "class ADE20K(BaseDataLoader):\n",
    "    def __init__(self, data_dir, batch_size, split, crop_size=None, base_size=None, scale=True, num_workers=1, val=False,\n",
    "                    shuffle=False, flip=False, rotate=False, blur= False, augment=False, val_split= None, return_id=False):\n",
    "\n",
    "        self.MEAN = [0.48897059, 0.46548275, 0.4294]\n",
    "        self.STD = [0.22861765, 0.22948039, 0.24054667]\n",
    "\n",
    "        kwargs = {\n",
    "            'root': data_dir,\n",
    "            'split': split,\n",
    "            'mean': self.MEAN,\n",
    "            'std': self.STD,\n",
    "            'augment': augment,\n",
    "            'crop_size': crop_size,\n",
    "            'base_size': base_size,\n",
    "            'scale': scale,\n",
    "            'flip': flip,\n",
    "            'blur': blur,\n",
    "            'rotate': rotate,\n",
    "            'return_id': return_id,\n",
    "            'val': val\n",
    "        }\n",
    "\n",
    "        self.dataset = ADE20KDataset(**kwargs)\n",
    "        super(ADE20K, self).__init__(self.dataset, batch_size, shuffle, num_workers, val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1d516",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training data loader\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mADE20K\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/path/to/your/ade20k/dataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcrop_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m520\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrotate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblur\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Validation data loader\u001b[39;00m\n\u001b[0;32m     18\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m ADE20K(\n\u001b[0;32m     19\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/path/to/your/ade20k/dataset\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     val\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     29\u001b[0m )\n",
      "Cell \u001b[1;32mIn[13], line 62\u001b[0m, in \u001b[0;36mADE20K.__init__\u001b[1;34m(self, data_dir, batch_size, split, crop_size, base_size, scale, num_workers, val, shuffle, flip, rotate, blur, augment, val_split, return_id)\u001b[0m\n\u001b[0;32m     45\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m'\u001b[39m: data_dir,\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m: split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m: val\n\u001b[0;32m     59\u001b[0m }\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m ADE20KDataset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mADE20K\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_split\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 165\u001b[0m, in \u001b[0;36mBaseDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, num_workers, val_split)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_sampler, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_sampler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset,\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: batch_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpin_memory\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    164\u001b[0m }\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28msuper\u001b[39m(BaseDataLoader, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(sampler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_sampler, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\CHIRANJIT\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:376\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 376\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    378\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\CHIRANJIT\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\utils\\data\\sampler.py:164\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "# Training data loader\n",
    "train_loader = ADE20K(\n",
    "    data_dir='/path/to/your/ade20k/dataset',\n",
    "    batch_size=16,\n",
    "    split='training',\n",
    "    crop_size=512,\n",
    "    base_size=520,\n",
    "    scale=True,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    "    flip=True,\n",
    "    rotate=True,\n",
    "    blur=True,\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "# Validation data loader\n",
    "val_loader = ADE20K(\n",
    "    data_dir='Desktop/UNET_ADEK20K/ade/ADEChallengeData2016/images/training/',\n",
    "    batch_size=16,\n",
    "    split='validation',\n",
    "    crop_size=512,\n",
    "    base_size=520,\n",
    "    scale=False,\n",
    "    num_workers=4,\n",
    "    shuffle=False,\n",
    "    augment=False,\n",
    "    val=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "775daf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from typing import Tuple, List, Optional\n",
    "import logging\n",
    "\n",
    "def compute_mIoU(pred: torch.Tensor, label: torch.Tensor, num_classes: int, ignore_index: int = -1) -> float:\n",
    "    \"\"\"\n",
    "    Compute mean Intersection over Union (mIoU) for semantic segmentation.\n",
    "    \n",
    "    Args:\n",
    "        pred: Predicted segmentation masks [N, H, W] or [N*H*W]\n",
    "        label: Ground truth masks [N, H, W] or [N*H*W]\n",
    "        num_classes: Number of classes\n",
    "        ignore_index: Index to ignore in computation\n",
    "        \n",
    "    Returns:\n",
    "        Mean IoU score\n",
    "    \"\"\"\n",
    "    pred = pred.view(-1)\n",
    "    label = label.view(-1)\n",
    "    \n",
    "    # Remove ignore_index pixels\n",
    "    if ignore_index is not None:\n",
    "        valid_mask = label != ignore_index\n",
    "        pred = pred[valid_mask]\n",
    "        label = label[valid_mask]\n",
    "    \n",
    "    ious = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = pred == cls\n",
    "        target_inds = label == cls\n",
    "        \n",
    "        intersection = (pred_inds & target_inds).sum().item()\n",
    "        union = (pred_inds | target_inds).sum().item()\n",
    "        \n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # Ignore classes not present\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "    \n",
    "    return np.nanmean(ious)\n",
    "\n",
    "def compute_mIoU_batch_efficient(pred: torch.Tensor, label: torch.Tensor, num_classes: int, \n",
    "                                ignore_index: int = -1) -> float:\n",
    "    \"\"\"\n",
    "    More efficient batch-wise mIoU computation using confusion matrix.\n",
    "    \"\"\"\n",
    "    pred = pred.view(-1)\n",
    "    label = label.view(-1)\n",
    "    \n",
    "    # Remove ignore_index pixels\n",
    "    if ignore_index is not None:\n",
    "        valid_mask = label != ignore_index\n",
    "        pred = pred[valid_mask]\n",
    "        label = label[valid_mask]\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    mask = (label >= 0) & (label < num_classes)\n",
    "    hist = torch.bincount(\n",
    "        num_classes * label[mask] + pred[mask],\n",
    "        minlength=num_classes ** 2\n",
    "    ).reshape(num_classes, num_classes).float()\n",
    "    \n",
    "    # Compute IoU for each class\n",
    "    diag = torch.diag(hist)\n",
    "    union = hist.sum(dim=1) + hist.sum(dim=0) - diag\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    ious = diag / torch.clamp(union, min=1e-8)\n",
    "    \n",
    "    # Return mean IoU, ignoring classes not present\n",
    "    valid_ious = ious[union > 0]\n",
    "    return valid_ious.mean().item() if len(valid_ious) > 0 else 0.0\n",
    "\n",
    "class SegmentationTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader, num_classes=150, \n",
    "                 lr=1e-4, ignore_index=-1, use_amp=True, log_interval=10):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.num_classes = num_classes\n",
    "        self.ignore_index = ignore_index\n",
    "        self.use_amp = use_amp\n",
    "        self.log_interval = log_interval\n",
    "        \n",
    "        # Setup optimizer and scheduler\n",
    "        self.optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        self.scheduler = optim.lr_scheduler.PolynomialLR(\n",
    "            self.optimizer, total_iters=100, power=0.9\n",
    "        )\n",
    "        \n",
    "        # Setup loss function with class weights if needed\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=ignore_index)\n",
    "        \n",
    "        # Setup mixed precision training\n",
    "        self.scaler = GradScaler() if use_amp else None\n",
    "        \n",
    "        # Tracking variables\n",
    "        self.best_miou = 0.0\n",
    "        self.train_losses = []\n",
    "        self.val_mious = []\n",
    "        \n",
    "    def train_epoch(self, epoch: int) -> Tuple[float, float]:\n",
    "        \"\"\"Train for one epoch.\"\"\"\n",
    "        self.model.train()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        start_time = time.time()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(self.train_loader):\n",
    "            images, labels = images.cuda(non_blocking=True), labels.cuda(non_blocking=True)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            if self.use_amp:\n",
    "                with autocast():\n",
    "                    outputs = self.model(images)\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                self.scaler.scale(loss).backward()\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "            else:\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Log progress\n",
    "            if batch_idx % self.log_interval == 0:\n",
    "                print(f'Epoch {epoch+1}, Batch {batch_idx}/{len(self.train_loader)}, '\n",
    "                      f'Loss: {loss.item():.4f}')\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        peak_memory = torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        \n",
    "        return avg_loss, epoch_time, peak_memory\n",
    "    \n",
    "    def validate(self) -> float:\n",
    "        \"\"\"Validate the model and compute mIoU.\"\"\"\n",
    "        self.model.eval()\n",
    "        all_ious = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for val_images, val_labels in self.val_loader:\n",
    "                val_images = val_images.cuda(non_blocking=True)\n",
    "                val_labels = val_labels.cuda(non_blocking=True)\n",
    "                \n",
    "                if self.use_amp:\n",
    "                    with autocast():\n",
    "                        preds = self.model(val_images)\n",
    "                else:\n",
    "                    preds = self.model(val_images)\n",
    "                \n",
    "                preds = torch.argmax(preds, dim=1)\n",
    "                \n",
    "                # Use the more efficient mIoU computation\n",
    "                iou = compute_mIoU_batch_efficient(\n",
    "                    preds, val_labels, self.num_classes, self.ignore_index\n",
    "                )\n",
    "                all_ious.append(iou)\n",
    "        \n",
    "        return np.mean(all_ious)\n",
    "    \n",
    "    def save_checkpoint(self, epoch: int, miou: float, filepath: str):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'best_miou': self.best_miou,\n",
    "            'miou': miou,\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_mious': self.val_mious\n",
    "        }\n",
    "        \n",
    "        if self.scaler:\n",
    "            checkpoint['scaler_state_dict'] = self.scaler.state_dict()\n",
    "        \n",
    "        torch.save(checkpoint, filepath)\n",
    "        print(f'Checkpoint saved to {filepath}')\n",
    "    \n",
    "    def train(self, num_epochs: int, save_dir: str = './checkpoints'):\n",
    "        \"\"\"Main training loop.\"\"\"\n",
    "        import os\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # Training\n",
    "            avg_loss, epoch_time, peak_memory = self.train_epoch(epoch)\n",
    "            self.train_losses.append(avg_loss)\n",
    "            \n",
    "            # Validation\n",
    "            avg_miou = self.validate()\n",
    "            self.val_mious.append(avg_miou)\n",
    "            \n",
    "            # Learning rate scheduling\n",
    "            self.scheduler.step()\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Print epoch summary\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "            print(f\"  Train Loss: {avg_loss:.4f}\")\n",
    "            print(f\"  Val mIoU: {avg_miou:.4f}\")\n",
    "            print(f\"  Time: {epoch_time:.2f}s\")\n",
    "            print(f\"  Peak Memory: {peak_memory:.2f} MB\")\n",
    "            print(f\"  Learning Rate: {current_lr:.2e}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Save best model\n",
    "            if avg_miou > self.best_miou:\n",
    "                self.best_miou = avg_miou\n",
    "                self.save_checkpoint(\n",
    "                    epoch, avg_miou, \n",
    "                    os.path.join(save_dir, 'best_model.pth')\n",
    "                )\n",
    "                print(f\"New best mIoU: {self.best_miou:.4f}\")\n",
    "            \n",
    "            # Save regular checkpoint every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                self.save_checkpoint(\n",
    "                    epoch, avg_miou,\n",
    "                    os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "                )\n",
    "        \n",
    "        print(f\"Training completed! Best mIoU: {self.best_miou:.4f}\")\n",
    "        return self.best_miou\n",
    "\n",
    "# Example usage:\n",
    "def main():\n",
    "    # Assuming you have model, train_loader, val_loader defined\n",
    "    # model = YourSegmentationModel(num_classes=150)\n",
    "    # train_loader = create_ade20k_dataloader(...)\n",
    "    # val_loader = create_ade20k_dataloader(...)\n",
    "    \n",
    "    trainer = SegmentationTrainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_classes=150,\n",
    "        lr=1e-4,\n",
    "        ignore_index=-1,  # or 255 for some datasets\n",
    "        use_amp=True,\n",
    "        log_interval=10\n",
    "    )\n",
    "    \n",
    "    best_miou = trainer.train(num_epochs=100, save_dir='./checkpoints')\n",
    "    print(f\"Final best mIoU: {best_miou:.4f}\")\n",
    "\n",
    "# For backward compatibility, here's the improved standalone version\n",
    "def improved_training_loop(model, train_loader, val_loader, num_epochs=100, num_classes=150):\n",
    "    \"\"\"Improved version of your original training loop.\"\"\"\n",
    "    \n",
    "    # Use AdamW with weight decay\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "    \n",
    "    # Add learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.PolynomialLR(optimizer, total_iters=num_epochs, power=0.9)\n",
    "    \n",
    "    # Use ignore_index=255 for ADE20K (common convention)\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "    \n",
    "    # Mixed precision training\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    best_miou = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        start_time = time.time()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.cuda(non_blocking=True), labels.cuda(non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Mixed precision forward pass\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Mixed precision backward pass\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        peak_memory = torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        iou_scores = []\n",
    "        with torch.no_grad():\n",
    "            for val_images, val_labels in val_loader:\n",
    "                val_images = val_images.cuda(non_blocking=True)\n",
    "                val_labels = val_labels.cuda(non_blocking=True)\n",
    "                \n",
    "                with autocast():\n",
    "                    preds = model(val_images)\n",
    "                preds = torch.argmax(preds, dim=1)\n",
    "                \n",
    "                # Use the more efficient mIoU computation\n",
    "                iou = compute_mIoU_batch_efficient(preds, val_labels, num_classes, ignore_index=255)\n",
    "                iou_scores.append(iou)\n",
    "        \n",
    "        avg_mIoU = np.mean(iou_scores)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_mIoU > best_miou:\n",
    "            best_miou = avg_mIoU\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f} | mIoU = {avg_mIoU:.4f} | \"\n",
    "              f\"Time = {end_time - start_time:.2f}s | Peak Mem = {peak_memory:.2f} MB | \"\n",
    "              f\"LR = {current_lr:.2e}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a8420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9937b009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c387738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
